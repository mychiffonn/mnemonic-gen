[project]
name = "linksys"
version = "0.3.0"
description = "Generate linguistically grounded mnemonics for English vocabulary"
authors = [{ name = "My Chiffon Nguyen", email = "chiffonng136@gmail.com" }]
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
  "bespokelabs-curator>=0.1.26",
  "datasets>=3.5.1", # Hugging Face datasets
  "huggingface-hub>=0.30.2",
  "matplotlib>=3.9.2",
  "peft>=0.15.2 ; sys_platform == 'linux'",
  "pandas>=2.2.2",
  "pre-commit>=3.2.0",
  "pydantic>=2.11.4",
  "python-dotenv>=1.1.0",
  "rich>=13.9.4", # format rich text
  "ruff>=0.11.8",
  "structlog>=25.3.0",
  "torch>=2.6.0; sys_platform == 'linux'",
  "transformers>=4.53.0; sys_platform == 'linux'",
  "trl>=0.11.4 ; sys_platform == 'linux'",
  "wandb>=0.19.10; sys_platform == 'linux'",
  "unsloth==2025.4.7 ; sys_platform == 'linux'",
  "unsloth_zoo==2025.4.4 ; sys_platform == 'linux'",
  "rapidfuzz>=3.13.0",
  "scipy>=1.15.2",
  "pydantic-settings>=2.9.1",
]
license = "Apache-2.0"
keywords = ["mnemonic", "mnemonic generation", "LLM", "language model", "chain of thought", "CoT", "synthetic data generation", "vocabulary learning", "vocabulary acquisition", "language learning", "natural language processing", "NLP", "machine learning", "ML", "deep learning", "DL", "AI", "artificial intelligence", "fine-tuning"]

[project.urls]
repository = "https://github.com/chiffonng/mnemonic-gen"
dataset    = "https://huggingface.co/collections/chiffonng/links-english-english-mnemonics-67563a0a1ab91e84e9827579"

# Development dependencies
[dependency-groups]
dev = [
    "mypy>=1.15.0",
    "pandas-stubs",
    "types-PyYAML"
]

[tool.ruff]
src            = ["src"]
target-version = "py311"

[tool.ruff.format]
docstring-code-format      = true # format code in docstrings
docstring-code-line-length = 88

[tool.ruff.lint]
exclude = ["*.ipynb", "data/*", "logs/*", "tmp/*", "venv/*"]
extend-select = [
  "B",   # flake8-bugbear, bugbear checks
  "D",   # pydocstyle, all functions and classes must have docstrings
  "I",   # isort
  "N", # pep8-naming conventions
  "PL", # pylint
  "PT",  # flakes8-pytest-style, pytest fixtures and style
  "PTH", # flake8-use-pathlib, use pathlib instead of os.path
]
extend-safe-fixes = [
  "ANN",  # missing type annotation
  "D",    # pydocstyle docstrings
  "DOC",  # pydoclint docstring conventions
  "F",    # pyflakes
  "I002", # missing import
  "ICN",  # import conventions
  "LOG",  # logging conventions
  "Q",    # flake8-quotes
]
extend-fixable = ["B", "D"]
ignore = [
  "T201", # print ok
  "T203", # print statement ok
  "F401", # unused imports ok
  "PLR2004" # pylint numeric constants
]
flake8-type-checking.quote-annotations = true
isort.case-sensitive = true
pydocstyle.convention = "google"
pycodestyle.max-doc-length = 88

[tool.ruff.lint.flake8-annotations] # type annotations
ignore-fully-untyped = true # ignore fully untyped functions
mypy-init-return = true  # omit return type in __init__ OK

[tool.ruff.lint.per-file-ignores]
"*/__init__.py" = ["D", "F401"]

[tool.uv]
python-downloads = "manual"         # change to "automatic" to download Python specified in .python-version
managed          = true

[tool.uv.pip]
upgrade-package  = ["ruff", "pre-commit"]

[tool.mypy]
files = ["src", "scripts"]
disable_error_code = [
  "attr-defined",
  "empty-body",
  "import-untyped",
  "no-redef",
]
